{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020b6e3a-d975-4a54-931c-15e92541a270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ts_polarity</th>\n",
       "      <th>twitter_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>25.65</td>\n",
       "      <td>26.34</td>\n",
       "      <td>25.50</td>\n",
       "      <td>26.34</td>\n",
       "      <td>24.44</td>\n",
       "      <td>270597600</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>1133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>26.44</td>\n",
       "      <td>26.46</td>\n",
       "      <td>25.60</td>\n",
       "      <td>25.68</td>\n",
       "      <td>23.83</td>\n",
       "      <td>223164000</td>\n",
       "      <td>0.133635</td>\n",
       "      <td>1430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>25.14</td>\n",
       "      <td>25.59</td>\n",
       "      <td>24.97</td>\n",
       "      <td>25.17</td>\n",
       "      <td>23.36</td>\n",
       "      <td>273829600</td>\n",
       "      <td>0.072042</td>\n",
       "      <td>1949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>24.67</td>\n",
       "      <td>25.03</td>\n",
       "      <td>24.11</td>\n",
       "      <td>24.11</td>\n",
       "      <td>22.38</td>\n",
       "      <td>324377600</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>2289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>24.64</td>\n",
       "      <td>24.78</td>\n",
       "      <td>24.19</td>\n",
       "      <td>24.24</td>\n",
       "      <td>22.50</td>\n",
       "      <td>283192000</td>\n",
       "      <td>0.051595</td>\n",
       "      <td>2235.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Open   High    Low  Close  Adj Close     Volume  ts_polarity  \\\n",
       "0  2016-01-04  25.65  26.34  25.50  26.34      24.44  270597600     0.070389   \n",
       "1  2016-01-05  26.44  26.46  25.60  25.68      23.83  223164000     0.133635   \n",
       "2  2016-01-06  25.14  25.59  24.97  25.17      23.36  273829600     0.072042   \n",
       "3  2016-01-07  24.67  25.03  24.11  24.11      22.38  324377600     0.074369   \n",
       "4  2016-01-08  24.64  24.78  24.19  24.24      22.50  283192000     0.051595   \n",
       "\n",
       "   twitter_volume  \n",
       "0          1133.0  \n",
       "1          1430.0  \n",
       "2          1949.0  \n",
       "3          2289.0  \n",
       "4          2235.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Read a pandas DataFrame\n",
    "aapl_df = pd.read_csv('../data/AAPL.csv')\n",
    "aapl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b43ff6-6ff3-410a-8005-ec4da89154c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                0\n",
      "Open                0\n",
      "High                0\n",
      "Low                 0\n",
      "Close               0\n",
      "Adj Close           0\n",
      "Volume              0\n",
      "ts_polarity       266\n",
      "twitter_volume    266\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "remaining_missing_values = aapl_df.isnull().sum()\n",
    "print(remaining_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4687d7c1-8b56-4118-8b4c-7e7f1a9c904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date              0\n",
      "Open              0\n",
      "High              0\n",
      "Low               0\n",
      "Close             0\n",
      "Adj Close         0\n",
      "Volume            0\n",
      "ts_polarity       0\n",
      "twitter_volume    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply linear interpolation to fill missing values\n",
    "aapl_df['ts_polarity'] = aapl_df['ts_polarity'].interpolate(method='linear')\n",
    "aapl_df['twitter_volume'] = aapl_df['twitter_volume'].interpolate(method='linear')\n",
    "# aapl_df['Open'] = aapl_df['Open'].interpolate(method='linear')\n",
    "# aapl_df['High'] = aapl_df['High'].interpolate(method='linear')\n",
    "# aapl_df['Low'] = aapl_df['Low'].interpolate(method='linear')\n",
    "# aapl_df['Close'] = aapl_df['Close'].interpolate(method='linear')\n",
    "# aapl_df['Adj Close'] = aapl_df['Adj Close'].interpolate(method='linear')\n",
    "# aapl_df['Volume'] = aapl_df['Volume'].interpolate(method='linear')\n",
    "\n",
    "# Check if there are any remaining missing values after interpolation\n",
    "remaining_missing_values = aapl_df.isnull().sum()\n",
    "print(remaining_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566d7748-d13a-4752-bde1-4acb0a3eec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_df['Date'] = pd.to_datetime(aapl_df['Date'])\n",
    "aapl_df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4751f938-641e-4816-a7f9-951c75caf0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ts_polarity</th>\n",
       "      <th>twitter_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>0.027370</td>\n",
       "      <td>0.029724</td>\n",
       "      <td>0.028939</td>\n",
       "      <td>0.033692</td>\n",
       "      <td>0.028678</td>\n",
       "      <td>0.461343</td>\n",
       "      <td>0.393205</td>\n",
       "      <td>0.135932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.034234</td>\n",
       "      <td>0.030767</td>\n",
       "      <td>0.029863</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.023278</td>\n",
       "      <td>0.364149</td>\n",
       "      <td>0.581540</td>\n",
       "      <td>0.174019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.023205</td>\n",
       "      <td>0.024038</td>\n",
       "      <td>0.023208</td>\n",
       "      <td>0.019118</td>\n",
       "      <td>0.467966</td>\n",
       "      <td>0.398128</td>\n",
       "      <td>0.240575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>0.018855</td>\n",
       "      <td>0.018338</td>\n",
       "      <td>0.016087</td>\n",
       "      <td>0.013710</td>\n",
       "      <td>0.010444</td>\n",
       "      <td>0.571541</td>\n",
       "      <td>0.405057</td>\n",
       "      <td>0.284175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>0.018594</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.016827</td>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.011506</td>\n",
       "      <td>0.487150</td>\n",
       "      <td>0.337240</td>\n",
       "      <td>0.277251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close  Adj Close    Volume  \\\n",
       "Date                                                                      \n",
       "2016-01-04  0.027370  0.029724  0.028939  0.033692   0.028678  0.461343   \n",
       "2016-01-05  0.034234  0.030767  0.029863  0.027778   0.023278  0.364149   \n",
       "2016-01-06  0.022939  0.023205  0.024038  0.023208   0.019118  0.467966   \n",
       "2016-01-07  0.018855  0.018338  0.016087  0.013710   0.010444  0.571541   \n",
       "2016-01-08  0.018594  0.016165  0.016827  0.014875   0.011506  0.487150   \n",
       "\n",
       "            ts_polarity  twitter_volume  \n",
       "Date                                     \n",
       "2016-01-04     0.393205        0.135932  \n",
       "2016-01-05     0.581540        0.174019  \n",
       "2016-01-06     0.398128        0.240575  \n",
       "2016-01-07     0.405057        0.284175  \n",
       "2016-01-08     0.337240        0.277251  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define columns to scale\n",
    "columns_to_scale = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'ts_polarity', 'twitter_volume']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the columns\n",
    "aapl_df[columns_to_scale] = scaler.fit_transform(aapl_df[columns_to_scale])\n",
    "aapl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44fcb66d-a83e-44eb-abab-f09bffcf7102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and validation sets\n",
    "train_size = int(len(aapl_df) * 0.8)  # 80% for training\n",
    "training_set = aapl_df.iloc[:train_size]\n",
    "validation_set = aapl_df.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e21d7281-3523-4330-b04b-0f961c25adc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'darts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdarts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeries\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdarts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBModel\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load your data into a DataFrame (assuming it's already loaded in `aapl_df`)\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'darts'"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import XGBModel\n",
    "\n",
    "# Load your data into a DataFrame (assuming it's already loaded in `aapl_df`)\n",
    "aapl_df.index = pd.to_datetime(aapl_df.index)  # Ensure the index is datetime\n",
    "\n",
    "frequency = 'D'\n",
    "# Create TimeSeries objects from the DataFrame\n",
    "target = TimeSeries.from_dataframe(aapl_df, value_cols=['Close'], freq=frequency)\n",
    "past_cov = TimeSeries.from_dataframe(aapl_df, value_cols=['Open', 'High', 'Low', 'Adj Close', 'Volume'], freq=frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2351ad-faee-455f-b3fe-56b836f6fc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in target: component\n",
      "Close    535\n",
      "dtype: int64\n",
      "NaNs in past_covariates: component\n",
      "Open         535\n",
      "High         535\n",
      "Low          535\n",
      "Adj Close    535\n",
      "Volume       535\n",
      "dtype: int64\n",
      "Infs in target: 0\n",
      "Infs in past_covariates: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert TimeSeries back to DataFrame to check for NaNs or Infs\n",
    "target_df = target.pd_dataframe()\n",
    "past_covariates_df = past_cov.pd_dataframe()\n",
    "\n",
    "# Checking for NaNs\n",
    "print(\"NaNs in target:\", target_df.isna().sum())\n",
    "print(\"NaNs in past_covariates:\", past_covariates_df.isna().sum())\n",
    "\n",
    "# Checking for Infs\n",
    "print(\"Infs in target:\", np.isinf(target_df.values).sum())\n",
    "print(\"Infs in past_covariates:\", np.isinf(past_covariates_df.values).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a184265-f753-4499-be5c-569393f473f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEO\\AppData\\Local\\Temp\\ipykernel_20456\\3172371903.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  target_df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\TEO\\AppData\\Local\\Temp\\ipykernel_20456\\3172371903.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  past_covariates_df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\TEO\\AppData\\Local\\Temp\\ipykernel_20456\\3172371903.py:8: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  target_df.fillna(method='ffill', inplace=True)  # or use another appropriate method\n",
      "C:\\Users\\TEO\\AppData\\Local\\Temp\\ipykernel_20456\\3172371903.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  past_covariates_df.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill NaNs with a method of your choice, here using forward fill as an example\n",
    "target_df.fillna(method='ffill', inplace=True)\n",
    "past_covariates_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Replace Infs with NaN and then fill or drop\n",
    "target_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "past_covariates_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "target_df.fillna(method='ffill', inplace=True)  # or use another appropriate method\n",
    "past_covariates_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Convert back to TimeSeries if necessary\n",
    "target = TimeSeries.from_dataframe(target_df)\n",
    "past_covariates = TimeSeries.from_dataframe(past_covariates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a515fe05-dc05-4926-96aa-fdefb7a691c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_visualize(model, train_target, train_covariates, test_target, test_covariates, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        model.fit(series=train_target, past_covariates=train_covariates, epochs=1, verbose=True)\n",
    "        predicted = model.predict(n=10, series=train_target, past_covariates=test_covariates)\n",
    "        \n",
    "        # Clear the previous output\n",
    "        #clear_output(wait=True)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        train_target.plot(label='Training data')\n",
    "        test_target.plot(label='Actual Test Data', color='orange')\n",
    "        predicted.plot(label='Predicted Test Data', color='red')\n",
    "\n",
    "        # Setting the limits for x-axis to zoom into the test period plus 10 days back into the training period\n",
    "        start_date = test_target.start_time() - pd.Timedelta(days=10)  # 10 days before the test data starts\n",
    "        end_date = test_target.end_time()  # End of the test data\n",
    "        plt.xlim(start_date, end_date)\n",
    "\n",
    "        plt.title(f'Comparison of Predictions and Actual Data - Epoch {epoch + 1}')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b558ad59-6d4e-48ba-92a0-8a41358cdc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEO\\anaconda3\\envs\\darts\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | encoder             | Linear              | 896   \n",
      "4 | positional_encoding | _PositionalEncoding | 0     \n",
      "5 | transformer         | Transformer         | 1.9 M \n",
      "6 | decoder             | Linear              | 1.3 K \n",
      "------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.416     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 62/62 [00:08<00:00,  6.97it/s, train_loss=0.0341]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 62/62 [00:08<00:00,  6.97it/s, train_loss=0.0341]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.82it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clear_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 33\u001b[0m\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m TransformerModel(\n\u001b[0;32m     17\u001b[0m     input_chunk_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     18\u001b[0m     output_chunk_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     lr_scheduler_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.5\u001b[39m}\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# model.fit(series=train_target, past_covariates=train_covariates)\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m train_and_visualize(model, train_target, train_covariates, test_target, test_covariates, n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Predict using the correct past covariate slice, ensuring we predict 10 days at a time\u001b[39;00m\n\u001b[0;32m     36\u001b[0m predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, series\u001b[38;5;241m=\u001b[39mtrain_target, past_covariates\u001b[38;5;241m=\u001b[39mtest_covariates)\n",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m, in \u001b[0;36mtrain_and_visualize\u001b[1;34m(model, train_target, train_covariates, test_target, test_covariates, n_epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, series\u001b[38;5;241m=\u001b[39mtrain_target, past_covariates\u001b[38;5;241m=\u001b[39mtest_covariates)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Clear the previous output\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     10\u001b[0m train_target\u001b[38;5;241m.\u001b[39mplot(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clear_output' is not defined"
     ]
    }
   ],
   "source": [
    "from darts.models import TransformerModel\n",
    "from darts import TimeSeries\n",
    "import torch\n",
    "\n",
    "# Adjusting the split to ensure that past_covariates cover at least 10 days before training starts\n",
    "train_target, temp_target = target.split_before(pd.Timestamp('2018-09-28'))\n",
    "train_covariates, temp_covariates = past_covariates.split_before(pd.Timestamp('2018-09-18'))  # Adjusted to include ten days prior\n",
    "\n",
    "# Ensuring the test covariates start from the adjusted earlier date\n",
    "test_covariates = temp_covariates.slice(pd.Timestamp('2018-09-18'), pd.Timestamp('2018-10-28'))\n",
    "\n",
    "# Adjusting the test target similarly to start from the same day as test covariates for clarity in example\n",
    "test_target = temp_target.slice(pd.Timestamp('2018-09-28'), pd.Timestamp('2018-10-28'))\n",
    "\n",
    "# Initialize and fit the Transformer model\n",
    "model = TransformerModel(\n",
    "    input_chunk_length=10,\n",
    "    output_chunk_length=10,\n",
    "    n_epochs=20,\n",
    "    d_model=128,\n",
    "    nhead=8,\n",
    "    num_encoder_layers=4,\n",
    "    num_decoder_layers=4,\n",
    "    dropout=0.1,\n",
    "    activation='gelu',\n",
    "    batch_size=16,\n",
    "    optimizer_cls=torch.optim.Adam,\n",
    "    optimizer_kwargs={'lr': 1e-4},\n",
    "    lr_scheduler_cls=torch.optim.lr_scheduler.StepLR,\n",
    "    lr_scheduler_kwargs={'step_size': 10, 'gamma': 0.5}\n",
    ")\n",
    "# model.fit(series=train_target, past_covariates=train_covariates)\n",
    "train_and_visualize(model, train_target, train_covariates, test_target, test_covariates, n_epochs=20)\n",
    "\n",
    "# Predict using the correct past covariate slice, ensuring we predict 10 days at a time\n",
    "predicted = model.predict(n=10, series=train_target, past_covariates=test_covariates)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "train_target.plot(label='Training data')\n",
    "test_target.plot(label='Actual Test Data', color='orange')\n",
    "predicted.plot(label='Predicted Test Data', color='red')\n",
    "plt.title('Comparison of Predictions and Actual Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca4ade5-d9b9-475a-bb6b-79f949200d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
